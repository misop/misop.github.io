
<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Perception-Aware Appearance Fabrication</title>
        <meta name="description" content="Michal Piovarci - personal website">
        <link rel="stylesheet" href="main.css">
		<link rel="icon" type="image/png" href="images/favicon.png"/>
    </head>
    <body>
        <div id="content" class="wrap">
            <div>
                <h1 style="text-align: center; font-size: 250%;">Perception-Aware Appearance Fabrication<br/><div style="font-size: 75%;">(FWF Lise Meitner M3319)</div><span style="font-size: 50%;">01.01.2022 - 31.12.2023</span></h1>
                <p style="text-align: justify;">Wouldn’t it be amazing to be able to mirror how an object looks? We could create appealing products, preserve cultural heritage, or create prosthetics undistinguishable from genuine body parts. One of the options to fabricate such objects is 3D printing. 3D printers are good at reproducing complex shapes, and some even print with multiple colors. Unfortunately, accurately reproducing the hue, saturation, and gloss does not work well yet. The main hurdle for printing objects with desired looks is how do we evaluate how an object looks like? We have devices that can measure individual attributes of an object. We can measure either object’s shape, color, or gloss. However, when we see an object, we do not observe these attributes separately. Instead, we see the entire object at once, and the shape, color, and gloss combine into a single feeling. Currently, it is unknown how this combination is done and how individual attributes play together. Therefore, the main objective of this work is to investigate how humans perceive the difference in looks and how we can leverage these insights in manufacturing.</p>
 
                <p style="text-align: justify;">To examine human perception of gloss we designed a display that could produce images so realistic that they were indistinguishable from real objects. With the display we could turn on and off individual components of gloss. We found that the key attribute to match virtual and real objects is accurate reproduction of the dynamic range, i.e. matching the strong highlights and the deep blacks of the real world. With these findings we designed a study that investigated the joined perception of color and gloss. The study revealed a simple, yet intuitive effect. The higher the gloss, the more saturated the color. We combined these insights into a single color-gloss management tool. Our tool automatically handless the saturation change between glossy finishes and produces a single consistent appearance. To deploy our algorithm we also require a manufacturing technology. We proposed a novel tattooing-based system that applies inks in silicon media with needle injections. The system is capable of accurately reproducing human skin tones and creating silicon prosthetics that mimic genuine body parts. To achieve such high fidelity with output we need fine control of the fabrication process. To this end, we developed a self-adjusting printing technology. We first create a digital twin of the printing device on a computer. By interacting with the digital printer a computer algorithm learns effective control strategies that can be applied to the real physical device. We showcased our full pipeline from design tool to production by manufacturing several prototypes from colored printouts to tattooed skin-like silicone sheets.</p>
            </div>
            <div>
                <h2>Publications</h2>
                <div class="project">
                    <a href="https://misop.github.io/projects/DisplayCapabilities/index.html"><img width="300" height="200" src="images/glossmanageStereoHDR.png" /></a>
                    <div>
                        <span class="projectTitle"><a href="https://misop.github.io/projects/DisplayCapabilities/index.html">The Effect of Display Capabilities on the Gloss Consistency Between Real and Virtual Objects</a></span><br />
                        <span class="projectAuthors">Bin Chen, Akshay Jindal, Michal Piovarci, Chao Wang, Hans-Peter Seidel, Piotr Didyk, Karol Myszkowski, Ana Serrano, Rafal K. Mantiuk</span> <br />
                        <span class="projectPlace">SIGGRAPH ASIA 2023</span>
                    </div>
                </div>
                <div class="project">
                    <a href="https://misop.github.io/projects/ComputationalTattoo/index.html"><img width="300" height="200" src="images/tattoo.png" /></a>
                    <div>
                        <span class="projectTitle"><a href="https://misop.github.io/projects/ComputationalTattoo/index.html">Skin-Screen: A Computational Fabrication Framework for Color Tattoos</a></span><br />
                        <span class="projectAuthors">Michal Piovarci, Alexandre Chapiro, Bernd Bickel</span> <br />
                        <span class="projectPlace">SIGGRAPH 2023</span>
                    </div>
                </div>
                <div class="project">
                    <a href="https://misop.github.io/projects/ColorGloss/index.html"><img width="300" height="200" src="images/colorgloss.png" /></a>
                    <div>
                        <span class="projectTitle"><a href="https://misop.github.io/projects/ColorGloss/index.html">Gloss-aware Color Correction for 3D Printing</a></span><br />
                        <span class="projectAuthors">Jorge Condor, Michal Piovarci, Bernd Bickel, Piotr Didyk</span> <br />
                        <span class="projectPlace">SIGGRAPH 2023</span>
                    </div>
                </div>
                <div class="project">
                    <a href="https://misop.github.io/projects/LearningMMFFD/index.html"><img width="300" height="200" src="images/learning_fdm.png" /></a>
                    <div>
                        <span class="projectTitle"><a href="https://misop.github.io/projects/LearningMMFFD/index.html">Learning Deposition Policies for Fused Multi-Material 3D Printing</a></span><br />
                        <span class="projectAuthors">Kang Liao*, Thibault Tricard*, Michal Piovarci, Hans-Peter Seidel, Vahid Babaei</span> <br />
                        <span class="projectPlace">ICRA 2023</span>
                    </div>
                </div>
                <div class="project">
                    <a href="https://misop.github.io/projects/Embroidery/index.html"><img width="300" height="200" src="images/embroidery.png" /></a>
                    <div>
                        <span class="projectTitle"><a href="https://misop.github.io/projects/Embroidery/index.html">Directionality-Aware Design of Embroidery Patterns </a></span><br />
                        <span class="projectAuthors">Liu Zhenyuan, Michal Piovarci, Christian Hafner, Raphael Charrondiere, Bernd Bickel</span> <br />
                        <span class="projectPlace">Eurographics 2023</span>
                    </div>
                </div>
                <div class="project">
                    <a href="https://misop.github.io/projects/GlossManage/index.html"><img width="300" height="200" src="images/gloss_manage.png" /></a>
                    <div>
                        <span class="projectTitle"><a href="https://misop.github.io/projects/GlossManage/index.html">Gloss Management For Consistent Reproduction of Real and Virtual Objects</a></span><br />
                        <span class="projectAuthors">Bin Chen, Michal Piovarci, Chao Wang, Hans-Peter Seidel, Piotr Didyk, Karol Myszkowski, Ana Serrano</span> <br />
                        <span class="projectPlace">SIGGRAPH ASIA 2022</span>
                    </div>
                </div>
                <div class="project">
                    <a href="https://misop.github.io/projects/DirectInkReinforcementLearning/index.html"><img width="300" height="200" src="images/dairectink.png" /></a>
                    <div>
                        <span class="projectTitle"><a href="https://misop.github.io/projects/DirectInkReinforcementLearning/index.html">Closed-Loop Control of Direct Ink Writing via Reinforcement Learning</a></span><br />
                        <span class="projectAuthors">Michal Piovarci*, Michael Foshey*, Jie Xu, Timothy Erps, Vahid Babaei, Piotr Didyk, Szymon Rusinkiewicz, Wojciech Matusik, Bernd Bickel</span> <br />
                        <span class="projectPlace">SIGGRAPH 2022</span>
                    </div>
                </div>
            </div>	
        <div id="footer" class="wrap">
        </div>
        </div>	
</html>
